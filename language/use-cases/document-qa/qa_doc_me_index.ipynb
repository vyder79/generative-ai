{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ac6e4dae-b060-490f-943c-d60bace60168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose, how werbose answer is expected\n",
    "VERBOSE = \"SIMPLE\" # SIMPLE, DEBUG\n",
    "\n",
    "PROJECT_ID = \"osa-hy-project\"\n",
    "REGION = \"europe-central2\"\n",
    "\n",
    "ME_REGION = \"europe-central2\"\n",
    "ME_INDEX_NAME = f\"{PROJECT_ID}-me-index\"\n",
    "ME_EMBEDDING_DIR = f\"{PROJECT_ID}-me-bucket\"\n",
    "ME_DIMENSIONS = 768  # when using Vertex PaLM Embedding\n",
    "\n",
    "# index and endpoint deployed in Vertex AI for PROJECT_ID\n",
    "ME_INDEX_ID = \"\"\n",
    "ME_INDEX_ENDPOINT_ID = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cececff7-5d69-4f84-a471-121e2e1333fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Vertex AI LLM SDK\n",
    "! pip install --user --upgrade google-cloud-aiplatform==1.31.0 langchain==0.0.201\n",
    "\n",
    "# For Matching Engine integration dependencies (default embeddings)\n",
    "! pip install --user tensorflow_hub==0.13.0 tensorflow_text==2.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ff8315b1-be00-4b0d-bd77-994eb805c082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI SDK version: 1.31.0\n",
      "LangChain version: 0.0.201\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import textwrap\n",
    "# Utils\n",
    "import time\n",
    "import uuid\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import vertexai\n",
    "# Vertex AI\n",
    "from google.cloud import aiplatform\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")\n",
    "\n",
    "# Langchain\n",
    "import langchain\n",
    "print(f\"LangChain version: {langchain.__version__}\")\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import GCSDirectoryLoader\n",
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.llms import VertexAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#add memory to conversation\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd088717-ccb3-403f-a439-ce94c193846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Vertex Matching Engine implementation of the vector store.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import uuid\n",
    "from typing import Any, Iterable, List, Optional, Type\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import TensorflowHubEmbeddings\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform import MatchingEngineIndex, MatchingEngineIndexEndpoint\n",
    "from google.cloud import aiplatform_v1\n",
    "from google.oauth2.service_account import Credentials\n",
    "import google.auth\n",
    "import google.auth.transport.requests\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "\n",
    "class MatchingEngine(VectorStore):\n",
    "    \"\"\"Vertex Matching Engine implementation of the vector store.\n",
    "\n",
    "    While the embeddings are stored in the Matching Engine, the embedded\n",
    "    documents will be stored in GCS.\n",
    "\n",
    "    An existing Index and corresponding Endpoint are preconditions for\n",
    "    using this module.\n",
    "\n",
    "    See usage in docs/modules/indexes/vectorstores/examples/matchingengine.ipynb\n",
    "\n",
    "    Note that this implementation is mostly meant for reading if you are\n",
    "    planning to do a real time implementation. While reading is a real time\n",
    "    operation, updating the index takes close to one hour.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        project_id: str,\n",
    "        region: str,\n",
    "        index: MatchingEngineIndex,\n",
    "        endpoint: MatchingEngineIndexEndpoint,\n",
    "        embedding: Embeddings,\n",
    "        gcs_client: storage.Client,\n",
    "        index_client: aiplatform_v1.IndexServiceClient,\n",
    "        index_endpoint_client: aiplatform_v1.IndexEndpointServiceClient,\n",
    "        gcs_bucket_name: str,\n",
    "        credentials: Credentials = None,\n",
    "    ):\n",
    "        \"\"\"Vertex Matching Engine implementation of the vector store.\n",
    "\n",
    "        While the embeddings are stored in the Matching Engine, the embedded\n",
    "        documents will be stored in GCS.\n",
    "\n",
    "        An existing Index and corresponding Endpoint are preconditions for\n",
    "        using this module.\n",
    "\n",
    "        See usage in\n",
    "        docs/modules/indexes/vectorstores/examples/matchingengine.ipynb.\n",
    "\n",
    "        Note that this implementation is mostly meant for reading if you are\n",
    "        planning to do a real time implementation. While reading is a real time\n",
    "        operation, updating the index takes close to one hour.\n",
    "\n",
    "        Attributes:\n",
    "            project_id: The GCS project id.\n",
    "            index: The created index class. See\n",
    "            ~:func:`MatchingEngine.from_components`.\n",
    "            endpoint: The created endpoint class. See\n",
    "            ~:func:`MatchingEngine.from_components`.\n",
    "            embedding: A :class:`Embeddings` that will be used for\n",
    "            embedding the text sent. If none is sent, then the\n",
    "            multilingual Tensorflow Universal Sentence Encoder will be used.\n",
    "            gcs_client: The Google Cloud Storage client.\n",
    "            credentials (Optional): Created GCP credentials.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._validate_google_libraries_installation()\n",
    "\n",
    "        self.project_id = project_id\n",
    "        self.region = region\n",
    "        self.index = index\n",
    "        self.endpoint = endpoint\n",
    "        self.embedding = embedding\n",
    "        self.gcs_client = gcs_client\n",
    "        self.index_client = index_client\n",
    "        self.index_endpoint_client = index_endpoint_client\n",
    "        self.gcs_client = gcs_client\n",
    "        self.credentials = credentials\n",
    "        self.gcs_bucket_name = gcs_bucket_name\n",
    "        logger.info(\"local helper functions used.\")\n",
    "\n",
    "    def _validate_google_libraries_installation(self) -> None:\n",
    "        \"\"\"Validates that Google libraries that are needed are installed.\"\"\"\n",
    "        try:\n",
    "            from google.cloud import aiplatform, storage  # noqa: F401\n",
    "            from google.oauth2 import service_account  # noqa: F401\n",
    "        except ImportError:\n",
    "            raise ImportError(\n",
    "                \"You must run `pip install --upgrade \"\n",
    "                \"google-cloud-aiplatform google-cloud-storage`\"\n",
    "                \"to use the MatchingEngine Vectorstore.\"\n",
    "            )\n",
    "\n",
    "    def add_texts(\n",
    "        self,\n",
    "        texts: Iterable[str],\n",
    "        metadatas: Optional[List[dict]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "\n",
    "        Args:\n",
    "            texts: Iterable of strings to add to the vectorstore.\n",
    "            metadatas: Optional list of metadatas associated with the texts.\n",
    "            kwargs: vectorstore specific parameters.\n",
    "\n",
    "        Returns:\n",
    "            List of ids from adding the texts into the vectorstore.\n",
    "        \"\"\"\n",
    "        logger.info(\"Embedding documents.\")\n",
    "        embeddings = self.embedding.embed_documents(list(texts))\n",
    "        insert_datapoints_payload = []\n",
    "        ids = []\n",
    "\n",
    "        # Streaming index update\n",
    "        for idx, (embedding, text, metadata) in enumerate(\n",
    "            zip(embeddings, texts, metadatas)\n",
    "        ):\n",
    "            id = uuid.uuid4()\n",
    "            ids.append(id)\n",
    "            self._upload_to_gcs(text, f\"documents/{id}\")\n",
    "            metadatas[idx]\n",
    "            insert_datapoints_payload.append(\n",
    "                aiplatform_v1.IndexDatapoint(\n",
    "                    datapoint_id=str(id),\n",
    "                    feature_vector=embedding,\n",
    "                    restricts=metadata if metadata else [],\n",
    "                )\n",
    "            )\n",
    "            if idx % 100 == 0:\n",
    "                upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "                    index=self.index.name, datapoints=insert_datapoints_payload\n",
    "                )\n",
    "                response = self.index_client.upsert_datapoints(request=upsert_request)\n",
    "                insert_datapoints_payload = []\n",
    "        if len(insert_datapoints_payload) > 0:\n",
    "            upsert_request = aiplatform_v1.UpsertDatapointsRequest(\n",
    "                index=self.index.name, datapoints=insert_datapoints_payload\n",
    "            )\n",
    "            _ = self.index_client.upsert_datapoints(request=upsert_request)\n",
    "\n",
    "        logger.info(\"Updated index with new configuration.\")\n",
    "        logger.info(f\"Indexed {len(ids)} documents to Matching Engine.\")\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def _upload_to_gcs(self, data: str, gcs_location: str) -> None:\n",
    "        \"\"\"Uploads data to gcs_location.\n",
    "\n",
    "        Args:\n",
    "            data: The data that will be stored.\n",
    "            gcs_location: The location where the data will be stored.\n",
    "        \"\"\"\n",
    "        bucket = self.gcs_client.get_bucket(self.gcs_bucket_name)\n",
    "        blob = bucket.blob(gcs_location)\n",
    "        blob.upload_from_string(data)\n",
    "\n",
    "    def get_matches(\n",
    "        self,\n",
    "        embeddings: List[str],\n",
    "        n_matches: int,\n",
    "        index_endpoint: MatchingEngineIndexEndpoint,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        get matches from matching engine given a vector query\n",
    "        Uses public endpoint\n",
    "\n",
    "        \"\"\"\n",
    "        import requests\n",
    "        import json\n",
    "\n",
    "        request_data = {\n",
    "            \"deployed_index_id\": index_endpoint.deployed_indexes[0].id,\n",
    "            \"return_full_datapoint\": True,\n",
    "            \"queries\": [\n",
    "                {\n",
    "                    \"datapoint\": {\"datapoint_id\": f\"{i}\", \"feature_vector\": emb},\n",
    "                    \"neighbor_count\": n_matches,\n",
    "                }\n",
    "                for i, emb in enumerate(embeddings)\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        endpoint_address = self.endpoint.public_endpoint_domain_name\n",
    "        rpc_address = f\"https://{endpoint_address}/v1beta1/{index_endpoint.resource_name}:findNeighbors\"\n",
    "        endpoint_json_data = json.dumps(request_data)\n",
    "\n",
    "        logger.debug(f\"Querying Matching Engine Index Endpoint {rpc_address}\")\n",
    "\n",
    "        request = google.auth.transport.requests.Request()\n",
    "        self.credentials.refresh(request)\n",
    "        header = {\"Authorization\": \"Bearer \" + self.credentials.token}\n",
    "\n",
    "        return requests.post(rpc_address, data=endpoint_json_data, headers=header)\n",
    "\n",
    "    def similarity_search(\n",
    "        self, query: str, k: int = 4, search_distance: float = 0.65, **kwargs: Any\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"Return docs most similar to query.\n",
    "\n",
    "        Args:\n",
    "            query: The string that will be used to search for similar documents.\n",
    "            k: The amount of neighbors that will be retrieved.\n",
    "            search_distance: filter search results by  search distance by adding a threshold value\n",
    "\n",
    "        Returns:\n",
    "            A list of k matching documents.\n",
    "        \"\"\"\n",
    "\n",
    "        logger.info(f\"Embedding query {query}.\")\n",
    "        embedding_query = self.embedding.embed_documents([query])\n",
    "        deployed_index_id = self._get_index_id()\n",
    "        logger.info(f\"Deployed Index ID = {deployed_index_id}\")\n",
    "\n",
    "        # TO-DO: Pending query sdk integration\n",
    "        # response = self.endpoint.match(\n",
    "        #     deployed_index_id=self._get_index_id(),\n",
    "        #     queries=embedding_query,\n",
    "        #     num_neighbors=k,\n",
    "        # )\n",
    "\n",
    "        response = self.get_matches(embedding_query, k, self.endpoint)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            response = response.json()[\"nearestNeighbors\"]\n",
    "        else:\n",
    "            raise Exception(f\"Failed to query index {str(response)}\")\n",
    "\n",
    "        if len(response) == 0:\n",
    "            return []\n",
    "\n",
    "        logger.info(f\"Found {len(response)} matches for the query {query}.\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # I'm only getting the first one because queries receives an array\n",
    "        # and the similarity_search method only recevies one query. This\n",
    "        # means that the match method will always return an array with only\n",
    "        # one element.\n",
    "        for doc in response[0][\"neighbors\"]:\n",
    "            page_content = self._download_from_gcs(\n",
    "                f\"documents/{doc['datapoint']['datapointId']}\"\n",
    "            )\n",
    "            metadata = {}\n",
    "            if \"restricts\" in doc[\"datapoint\"]:\n",
    "                metadata = {\n",
    "                    item[\"namespace\"]: item[\"allowList\"][0]\n",
    "                    for item in doc[\"datapoint\"][\"restricts\"]\n",
    "                }\n",
    "            if \"distance\" in doc:\n",
    "                metadata[\"score\"] = doc[\"distance\"]\n",
    "                if doc[\"distance\"] >= search_distance:\n",
    "                    results.append(\n",
    "                        Document(page_content=page_content, metadata=metadata)\n",
    "                    )\n",
    "            else:\n",
    "                results.append(Document(page_content=page_content, metadata=metadata))\n",
    "\n",
    "        logger.info(\"Downloaded documents for query.\")\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _get_index_id(self) -> str:\n",
    "        \"\"\"Gets the correct index id for the endpoint.\n",
    "\n",
    "        Returns:\n",
    "            The index id if found (which should be found) or throws\n",
    "            ValueError otherwise.\n",
    "        \"\"\"\n",
    "        for index in self.endpoint.deployed_indexes:\n",
    "            if index.index == self.index.name:\n",
    "                return index.id\n",
    "\n",
    "        raise ValueError(\n",
    "            f\"No index with id {self.index.name} \"\n",
    "            f\"deployed on enpoint \"\n",
    "            f\"{self.endpoint.display_name}.\"\n",
    "        )\n",
    "\n",
    "    def _download_from_gcs(self, gcs_location: str) -> str:\n",
    "        \"\"\"Downloads from GCS in text format.\n",
    "\n",
    "        Args:\n",
    "            gcs_location: The location where the file is located.\n",
    "\n",
    "        Returns:\n",
    "            The string contents of the file.\n",
    "        \"\"\"\n",
    "        bucket = self.gcs_client.get_bucket(self.gcs_bucket_name)\n",
    "        try:\n",
    "            blob = bucket.blob(gcs_location)\n",
    "            return blob.download_as_string()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_texts(\n",
    "        cls: Type[\"MatchingEngine\"],\n",
    "        texts: List[str],\n",
    "        embedding: Embeddings,\n",
    "        metadatas: Optional[List[dict]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"MatchingEngine\":\n",
    "        \"\"\"Use from components instead.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"This method is not implemented. Instead, you should initialize the class\"\n",
    "            \" with `MatchingEngine.from_components(...)` and then call \"\n",
    "            \"`from_texts`\"\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_documents(\n",
    "        cls: Type[\"MatchingEngine\"],\n",
    "        documents: List[str],\n",
    "        embedding: Embeddings,\n",
    "        metadatas: Optional[List[dict]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"MatchingEngine\":\n",
    "        \"\"\"Use from components instead.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"This method is not implemented. Instead, you should initialize the class\"\n",
    "            \" with `MatchingEngine.from_components(...)` and then call \"\n",
    "            \"`from_documents`\"\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_components(\n",
    "        cls: Type[\"MatchingEngine\"],\n",
    "        project_id: str,\n",
    "        region: str,\n",
    "        gcs_bucket_name: str,\n",
    "        index_id: str,\n",
    "        endpoint_id: str,\n",
    "        credentials_path: Optional[str] = None,\n",
    "        embedding: Optional[Embeddings] = None,\n",
    "    ) -> \"MatchingEngine\":\n",
    "        \"\"\"Takes the object creation out of the constructor.\n",
    "\n",
    "        Args:\n",
    "            project_id: The GCP project id.\n",
    "            region: The default location making the API calls. It must have\n",
    "            the same location as the GCS bucket and must be regional.\n",
    "            gcs_bucket_name: The location where the vectors will be stored in\n",
    "            order for the index to be created.\n",
    "            index_id: The id of the created index.\n",
    "            endpoint_id: The id of the created endpoint.\n",
    "            credentials_path: (Optional) The path of the Google credentials on\n",
    "            the local file system.\n",
    "            embedding: The :class:`Embeddings` that will be used for\n",
    "            embedding the texts.\n",
    "\n",
    "        Returns:\n",
    "            A configured MatchingEngine with the texts added to the index.\n",
    "        \"\"\"\n",
    "        gcs_bucket_name = cls._validate_gcs_bucket(gcs_bucket_name)\n",
    "\n",
    "        # Set credentials\n",
    "        if credentials_path:\n",
    "            credentials = cls._create_credentials_from_file(credentials_path)\n",
    "        else:\n",
    "            credentials, _ = google.auth.default()\n",
    "            request = google.auth.transport.requests.Request()\n",
    "            credentials.refresh(request)\n",
    "\n",
    "        index = cls._create_index_by_id(index_id, project_id, region, credentials)\n",
    "        endpoint = cls._create_endpoint_by_id(\n",
    "            endpoint_id, project_id, region, credentials\n",
    "        )\n",
    "\n",
    "        gcs_client = cls._get_gcs_client(credentials, project_id)\n",
    "        index_client = cls._get_index_client(project_id, region, credentials)\n",
    "        index_endpoint_client = cls._get_index_endpoint_client(\n",
    "            project_id, region, credentials\n",
    "        )\n",
    "        cls._init_aiplatform(project_id, region, gcs_bucket_name, credentials)\n",
    "\n",
    "        return cls(\n",
    "            project_id=project_id,\n",
    "            region=region,\n",
    "            index=index,\n",
    "            endpoint=endpoint,\n",
    "            embedding=embedding or cls._get_default_embeddings(),\n",
    "            gcs_client=gcs_client,\n",
    "            index_client=index_client,\n",
    "            index_endpoint_client=index_endpoint_client,\n",
    "            credentials=credentials,\n",
    "            gcs_bucket_name=gcs_bucket_name,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _validate_gcs_bucket(cls, gcs_bucket_name: str) -> str:\n",
    "        \"\"\"Validates the gcs_bucket_name as a bucket name.\n",
    "\n",
    "        Args:\n",
    "              gcs_bucket_name: The received bucket uri.\n",
    "\n",
    "        Returns:\n",
    "              A valid gcs_bucket_name or throws ValueError if full path is\n",
    "              provided.\n",
    "        \"\"\"\n",
    "        gcs_bucket_name = gcs_bucket_name.replace(\"gs://\", \"\")\n",
    "        if \"/\" in gcs_bucket_name:\n",
    "            raise ValueError(\n",
    "                f\"The argument gcs_bucket_name should only be \"\n",
    "                f\"the bucket name. Received {gcs_bucket_name}\"\n",
    "            )\n",
    "        return gcs_bucket_name\n",
    "\n",
    "    @classmethod\n",
    "    def _create_credentials_from_file(\n",
    "        cls, json_credentials_path: Optional[str]\n",
    "    ) -> Optional[Credentials]:\n",
    "        \"\"\"Creates credentials for GCP.\n",
    "\n",
    "        Args:\n",
    "             json_credentials_path: The path on the file system where the\n",
    "             credentials are stored.\n",
    "\n",
    "         Returns:\n",
    "             An optional of Credentials or None, in which case the default\n",
    "             will be used.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.oauth2 import service_account\n",
    "\n",
    "        credentials = None\n",
    "        if json_credentials_path is not None:\n",
    "            credentials = service_account.Credentials.from_service_account_file(\n",
    "                json_credentials_path\n",
    "            )\n",
    "\n",
    "        return credentials\n",
    "\n",
    "    @classmethod\n",
    "    def _create_index_by_id(\n",
    "        cls, index_id: str, project_id: str, region: str, credentials: \"Credentials\"\n",
    "    ) -> MatchingEngineIndex:\n",
    "        \"\"\"Creates a MatchingEngineIndex object by id.\n",
    "\n",
    "        Args:\n",
    "            index_id: The created index id.\n",
    "\n",
    "        Returns:\n",
    "            A configured MatchingEngineIndex.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform_v1\n",
    "\n",
    "        logger.debug(f\"Creating matching engine index with id {index_id}.\")\n",
    "        index_client = cls._get_index_client(project_id, region, credentials)\n",
    "        request = aiplatform_v1.GetIndexRequest(name=index_id)\n",
    "        return index_client.get_index(request=request)\n",
    "\n",
    "    @classmethod\n",
    "    def _create_endpoint_by_id(\n",
    "        cls, endpoint_id: str, project_id: str, region: str, credentials: \"Credentials\"\n",
    "    ) -> MatchingEngineIndexEndpoint:\n",
    "        \"\"\"Creates a MatchingEngineIndexEndpoint object by id.\n",
    "\n",
    "        Args:\n",
    "            endpoint_id: The created endpoint id.\n",
    "\n",
    "        Returns:\n",
    "            A configured MatchingEngineIndexEndpoint.\n",
    "            :param project_id:\n",
    "            :param region:\n",
    "            :param credentials:\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform\n",
    "\n",
    "        logger.debug(f\"Creating endpoint with id {endpoint_id}.\")\n",
    "        return aiplatform.MatchingEngineIndexEndpoint(\n",
    "            index_endpoint_name=endpoint_id,\n",
    "            project=project_id,\n",
    "            location=region,\n",
    "            credentials=credentials,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _get_gcs_client(\n",
    "        cls, credentials: \"Credentials\", project_id: str\n",
    "    ) -> \"storage.Client\":\n",
    "        \"\"\"Lazily creates a GCS client.\n",
    "\n",
    "        Returns:\n",
    "            A configured GCS client.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import storage\n",
    "\n",
    "        return storage.Client(credentials=credentials, project=project_id)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_index_client(\n",
    "        cls, project_id: str, region: str, credentials: \"Credentials\"\n",
    "    ) -> \"storage.Client\":\n",
    "        \"\"\"Lazily creates a Matching Engine Index client.\n",
    "\n",
    "        Returns:\n",
    "            A configured Matching Engine Index client.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform_v1\n",
    "\n",
    "        # PARENT = f\"projects/{project_id}/locations/{region}\"\n",
    "        ENDPOINT = f\"{region}-aiplatform.googleapis.com\"\n",
    "        return aiplatform_v1.IndexServiceClient(\n",
    "            client_options=dict(api_endpoint=ENDPOINT), credentials=credentials\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _get_index_endpoint_client(\n",
    "        cls, project_id: str, region: str, credentials: \"Credentials\"\n",
    "    ) -> \"storage.Client\":\n",
    "        \"\"\"Lazily creates a Matching Engine Index Endpoint client.\n",
    "\n",
    "        Returns:\n",
    "            A configured Matching Engine Index Endpoint client.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform_v1\n",
    "\n",
    "        # PARENT = f\"projects/{project_id}/locations/{region}\"\n",
    "        ENDPOINT = f\"{region}-aiplatform.googleapis.com\"\n",
    "        return aiplatform_v1.IndexEndpointServiceClient(\n",
    "            client_options=dict(api_endpoint=ENDPOINT), credentials=credentials\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _init_aiplatform(\n",
    "        cls,\n",
    "        project_id: str,\n",
    "        region: str,\n",
    "        gcs_bucket_name: str,\n",
    "        credentials: \"Credentials\",\n",
    "    ) -> None:\n",
    "        \"\"\"Configures the aiplatform library.\n",
    "\n",
    "        Args:\n",
    "            project_id: The GCP project id.\n",
    "            region: The default location making the API calls. It must have\n",
    "            the same location as the GCS bucket and must be regional.\n",
    "            gcs_bucket_name: GCS staging location.\n",
    "            credentials: The GCS Credentials object.\n",
    "        \"\"\"\n",
    "\n",
    "        from google.cloud import aiplatform\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Initializing AI Platform for project {project_id} on \"\n",
    "            f\"{region} and for {gcs_bucket_name}.\"\n",
    "        )\n",
    "        aiplatform.init(\n",
    "            project=project_id,\n",
    "            location=region,\n",
    "            staging_bucket=gcs_bucket_name,\n",
    "            credentials=credentials,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _get_default_embeddings(cls) -> TensorflowHubEmbeddings:\n",
    "        \"\"\"This function returns the default embedding.\"\"\"\n",
    "        return TensorflowHubEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca2a643e-4aac-410e-8a21-f4d101b00f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text model instance integrated with langChain\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison@001\",\n",
    "    max_output_tokens=512,\n",
    "    temperature=0.2,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Embeddings API integrated with langChain (initially EMBEDDING_QPM=100 and EMBEDDING_NUM_BATCH=5)\n",
    "EMBEDDING_QPM = 50\n",
    "EMBEDDING_NUM_BATCH = 4\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko-multilingual\",\n",
    "    requests_per_minute=EMBEDDING_QPM,\n",
    "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
    ")\n",
    "\n",
    "# initialize vector store\n",
    "me = MatchingEngine.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=ME_REGION,\n",
    "    gcs_bucket_name=f\"gs://{ME_EMBEDDING_DIR}\".split(\"/\")[2],\n",
    "    embedding=embeddings,\n",
    "    index_id=ME_INDEX_ID,\n",
    "    endpoint_id=ME_INDEX_ENDPOINT_ID,\n",
    ")\n",
    "\n",
    "# Create chain to answer questions\n",
    "NUMBER_OF_RESULTS = 10\n",
    "SEARCH_DISTANCE_THRESHOLD = 0.65\n",
    "\n",
    "# Expose index to the retriever\n",
    "retriever = me.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": NUMBER_OF_RESULTS,\n",
    "        \"search_distance\": SEARCH_DISTANCE_THRESHOLD,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7a1cb03f-f2e2-4f43-844b-f82df3f95642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Nawozy jedno i wieloskładnikowe\\n\\nKażda z roślin uprawnych posiada dość specyficzne potrzeby pokarmowe w stosunku do makro- i mikroelementów. Oznacza to, że w agrotechnice uprawy należy uwzględnić oprócz nawożenia uniwersalnymi nawozami dolistnymi także aplikację dedykowanych produktów. Preparaty te zawierają wysoką koncentrację składników kluczowych dla danej rośliny uprawnej np. dla rzepaku ozimego może być to bor, natomiast dla kukurydzy cynk.\\n\\nTermin aplikacji nawozów dolistnych', metadata={'source': 'osa-hy-project-documents/documents/osa-txt', 'document_name': 'oferta-srodki-ochrony-roslin-nawozy.html', 'chunk': '58', 'score': 0.8309053182601929}),\n",
       " Document(page_content='Ilość zarejestrowanych herbicydów w uprawie kukurydzy umożliwia aplikację środków w bardzo szerokim zakresie faz rozwojowych. Począwszy od zabiegów przed wschodami, a kończąc na fazie 9-liści kukurydzy. Praktyka rolnicza i liczne doniesienia naukowe wskazują, że oprysk na chwasty należy wykonać maksymalnie do fazy 4-5 liścia kukurydzy.\\n\\nW rzepaku ozimym środki ochron roślin z grupy herbicydów powinny być stosowane w okresie jesiennym. Zabieg wiosenny jest rzadkością i służy głównie \"poprawce\" przy niewystarczającej skuteczności aplikacji jesiennej.\\n\\nPopularne w ograniczaniu zachwaszczenia w rzepaku są produkty zawierające substancję czynną chlomazon. Mają one jednak dość ograniczony termin aplikacji, maksymalnie do 3 dni po siewie. Dużą większą elastyczność stosowania mają produkty zawierające metazachlor. Wykorzystywane są one do zabiegów przed i po wschodach rzepaku.\\n\\nJaki preparaty na chwasty dwuliścienne wybrać?', metadata={'source': 'osa-hy-project-documents/documents/osa-txt', 'document_name': 'oferta-srodki-ochrony-roslin-chwasty-dwuliscienne.html', 'chunk': '22', 'score': 0.8147186040878296})]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "# Test whether search from vector store is working\n",
    "me.similarity_search(\"jakie są nawozy do rzepaku?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca42e8-e2d2-4949-8ac2-271f9d2e2ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "60562a72-2e91-435e-8ec3-803cdf29e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"SYSTEM: Dzień dobry. Jestem pomocnym agentem, który pomaga w odszukaniu informacji na zadane pytanie: {question}.\n",
    "\n",
    "Jako asystent mogę używać TYLKO i wyłącznie kontekstu zawartego pomiędzy znacznikami <CONTEXT></CONTEXT> aby odpowiadać na pytania. \n",
    "\n",
    "Nie generuję odpowiedzi dla poniższych przypadków:\n",
    " - jeśli odpowiedź na pytanie nie może zostać udzielona wyłącznie na podstawie kontekstu, odpowiadam \"nie posiadam informacji aby udzielić odpowiedzi na to pytanie.\"\n",
    " - jeśli kontekst jest pusty odpowiadam \"nie znam odpowedzi.\"\n",
    "\n",
    "================\n",
    "<CONTEXT>{context}</CONTEXT>\n",
    "================\n",
    "<CHAT_HISTORY>{chat_history}</CHAT_HISTORY>\n",
    "================\n",
    "\n",
    "Pytanie: {question}\n",
    "Odpowiedź:\"\"\"\n",
    "\n",
    "\n",
    "#add memory to the conversation\n",
    "#memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
    "memory =  ConversationBufferMemory(\n",
    "            memory_key=\"chat_history\",\n",
    "            input_key=\"question\")\n",
    "\n",
    "# Uses LLM to synthesize results from the search index.\n",
    "# Use Vertex PaLM Text API for LLM\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": False,\n",
    "        \"memory\": memory,\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5ad85019-7003-4cd7-9ddf-495644e1673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable for troubleshooting\n",
    "if VERBOSE == \"SIMPLE\":\n",
    "    enabled = False\n",
    "else:\n",
    "    enabled = True\n",
    "\n",
    "\n",
    "qa.combine_documents_chain.verbose = enabled\n",
    "qa.combine_documents_chain.llm_chain.verbose = enabled\n",
    "qa.combine_documents_chain.llm_chain.llm.verbose = enabled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4e0c8b11-6b1f-4f35-b9e0-753d44a9a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatter(result):\n",
    "    print(f\"Query: {result['query']}\")\n",
    "    print(\".\" * 80)\n",
    "    if \"source_documents\" in result.keys():\n",
    "        for idx, ref in enumerate(result[\"source_documents\"]):\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"REFERENCE #{idx}\")\n",
    "            print(\"-\" * 60)\n",
    "            if \"score\" in ref.metadata:\n",
    "                print(f\"Matching Score: {ref.metadata['score']}\")\n",
    "            if \"source\" in ref.metadata:\n",
    "                print(f\"Document Source: {ref.metadata['source']}\")\n",
    "            if \"document_name\" in ref.metadata:\n",
    "                print(f\"Document Name: {ref.metadata['document_name']}\")\n",
    "            print(f\"Content: \\n{wrap(ref.page_content)}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Response: {wrap(result['result'])}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "def wrap(s):\n",
    "    return \"\\n\".join(textwrap.wrap(s, width=120, break_long_words=False))\n",
    "\n",
    "\n",
    "def ask(query, qa=qa, k=NUMBER_OF_RESULTS, search_distance=SEARCH_DISTANCE_THRESHOLD):\n",
    "    qa.retriever.search_kwargs[\"search_distance\"] = search_distance\n",
    "    qa.retriever.search_kwargs[\"k\"] = k\n",
    "    result = qa({\"query\": query})\n",
    "    \n",
    "    if VERBOSE == \"SIMPLE\":\n",
    "        return result['result']\n",
    "    else:\n",
    "        return formatter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23ea45fe-a9f0-4bce-ab4b-495b7bd23b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adiuwanty, zwane również kondycjonerami wody, są to preparaty dodawane do zbiornika opryskiwacza w trakcie przygotowania cieczy opryskowej. Ich działanie polega na modyfikacji właściwości wody, tak aby były optymalne dla danej grupy środków ochrony roślin.\\n\\nAdiuwanty mogą wpływać na:\\n\\n- Modyfikacje pH cieczy opryskowej i redukcję twardości wody\\n\\n- Polepszenie mieszalności i trwałości cieczy opryskowej przygotowanej z kilku produktów\\n\\n- Zwiększenie równomierności i trwałości pokrycia traktowanej powierzchni\\n\\n- Ograniczenie pienienia ciecz użytkowej\\n\\nOsobną grupę stanowią adiuwanty wbudowane w formę użytkową produktu, są one jego ważnym elementem. Spełniają bardzo ważną funkcję związaną głównie z utrzymaniem jakości i trwałości konkretnego środka ochrony roślin, a dopiero w dalszej kolejności ich zadaniem jest modyfikacja właściwości cieczy opryskowej. Również ich ilość jest determinowana przez dawkę produktu na hektar i często jest niewystarczająca, stąd też zalecenia producentów dotyczące konieczności dodatku adiuwantów zewnętrznych.\\n\\nDlatego też w praktyce rolniczej bardzo dużą rolę odgrywają adiuwanty dodawane w trackie przygotowania tank mix z różnych produktów, które mogą być stosowane łącznie w trakcie jednego przejazdu.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('co to są adiuwanty?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e32f5d0-583c-4a6a-99b7-84567861e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Herbicydy to środki ochrony roślin przeznaczone do zwalczania chwastów w roślinach uprawnych. Chwastami mogą być samosiewy wcześniejszych upraw (m.in. rzepaku ozimego, zbóż i innych) lub rośliny dziko rosnące.\\n\\nChwasty konkurują z rośliną uprawną o wodę, składniki pokarmowe, dostęp do światła oraz przestrzeń w łanie. Obecność chwastów w uprawie zagęszcza łan. Ogranicza to jego przewietrzanie, co stwarza lepsze warunku do rozwoju chorób. Silna presja ze strony chwastów może powodować nadmierny wzrost roślin uprawnych na wysokość, w efekcie czego zmniejsza się zimotrwałość ozimin oraz rośnie ryzyko wylegania.\\n\\nHerbicydy, zwane środkami chwastobójczymi są podstawą agrotechniki i wykorzystuje się je do usuwania roślinności niepożądanej. Chwasty lepiej wykorzystują zasoby środowiska do wzrostu i rozwoju, w efekcie czego dominują nad roślinami uprawnymi. Dlatego znacznie ograniczają ilość i jakość plonu uprawianych roślin.\\n\\nHerbicydy zawierają substancję czynną, która jest biologicznie aktywna - wykazuje skuteczność w kierunku zwalczania chwastów. Substancje czynne wpływają na procesy fizjologiczne zachodzące w chwastach. Efektem tego jest zahamowanie wzrostu i rozwoju, a w konsekwencji ich zamieranie. Działanie herbicydu może być widoczne już nawet po kilku godzinach od oprysku, ale również po paru dniach. Substancje czynne, ze względu na miejsce działania i wpływu na określone procesy fizjologiczne (tzw. mechanizm działania) zostały sklasyfikowane i opisane w tzw. grupy HRAC.\\n\\nSubstancje czynne mogą mieć różne nazwy, ale ten sam mechanizm działania. Przy wyborze produktów warto uwzględnić rotację mechanizmami działania, czyli stosować środki chwastobójcze z różnych grup wg HRAC. Takie postępowanie jest podstawą strategii przeciwdziałania odporności chwastów na środki ochrony roślin z grupy herbicydów.\\n\\nHerbicydy doglebowe pobierane są głównie przez korzenie kiełkujących chwastów, liścienie lub '"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('jak działają herbicydy?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7f39c834-1e54-4233-ab2a-f0cbd4204e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nawozy mogą być dedykowane lub uniwersalne. Ważne jest, aby mikroelementy były w formie chelatów, wówczas będą najszybciej pobrane przez rozwijające się siewki.\\n\\nZ kolei makroelementy powinny być w rozpuszczalne w wodzie. Zwiększa to ich mobilność i pobranie przez kiełkujące nasiona. Nawóz powinien charakteryzować się wysoką zawartością fosforu oraz potasu.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"jaki nawóz mogę zastosować w uprawie pszenicy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7cb29488-6f26-476d-8e61-cd18d5c40b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OSD Fosfor\\n\\nWIĘCEJ\\n\\nNawóz dolistny mineralny NPK mikroelementy o wysokiej zawartości fosforu.12 lipca 2015'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"podaj przykładowy nawóz spełniający powyższe kryteria?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b676dd2-137d-4172-afb6-5fcaf661dc3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nie posiadam informacji aby udzielić odpowiedzi na to pytanie.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"podaj mi skład tego nawozu?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f89fffa-e837-445d-9c2b-0f34ddd8b5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zasilacz impulsowy - rodzaj zasilacza, który wykorzystuje przetwornicę impulsową do konwersji napięcia przemiennego na napięcie stałe. Zasilacze impulsowe są powszechnie stosowane w elektronice, ponieważ są wydajniejsze i mniejsze niż tradycyjne zasilacze liniowe.\\n\\nZasilacz impulsowy składa się z następujących elementów:\\n\\n* Przetwornica impulsowa - przekształca napięcie przemienne na napięcie stałe.\\n* Filtr wyjściowy - wygładza napięcie wyjściowe przetwornicy.\\n* Regulator napięcia - utrzymuje napięcie wyjściowe na stałym poziomie.\\n\\nZasilacze impulsowe są wydajniejsze niż tradycyjne zasilacze liniowe, ponieważ przetwornica impulsowa przekształca napięcie przemienne na napięcie stałe w sposób bardziej efektywny. Zasilacze impulsowe są również mniejsze niż tradycyjne zasilacze liniowe, ponieważ przetwornica impulsowa jest mniejsza niż transformator.\\n\\nZasilacze impulsowe są powszechnie stosowane w elektronice, ponieważ są wydajniejsze i mniejsze niż tradycyjne zasilacze liniowe. Zasilacze impulsowe są używane w szerokim zakresie urządzeń elektronicznych, w tym w komputerach, telewizorach, telefonach komórkowych i innych urządzeniach.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"co to jest zasilacz impulsowy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64804012-71f3-4346-9df9-03359b6fd5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6674aec-3d13-47be-a82e-10d32f2acf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
